{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau,TensorBoard\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import cv2\n",
    "import json\n",
    "from fastai_utils import *\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "from model_utils import *\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "os.chdir('/data/data_backup_affine/Data_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "nb_epoch = 5\n",
    "train_data_path = \"./final_train\"\n",
    "validation_data_path = \"./final_validation\"\n",
    "test_path = \"./final_test\"\n",
    "annotation_path = \"./final_data_annotation.csv\"\n",
    "model_weights_path = \"./models/model_weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "img_channels = 3\n",
    "img_rows = 224\n",
    "img_cols = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assign GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_split_1 = 'res4a_branch2a'\n",
    "model_split_2 = 'fc_start'\n",
    "\n",
    "## Defining model name\n",
    "date = datetime.now().strftime(\"%m%d%Y\")\n",
    "model_name = 'resnet50_multioutput_noaug'\n",
    "save_model_path = './models/iterations/' + date + '_' + model_name + '/'\n",
    "if not os.path.exists(save_model_path):\n",
    "    os.mkdir(save_model_path)\n",
    "    \n",
    "save_model_path = \"./models/iterations/imgaug_1552532559/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading Data Annotation\n",
    "data = pd.read_csv(annotation_path, encoding = 'latin-1')\n",
    "\n",
    "## Encoding the classes\n",
    "def one_hot_categorical(x, classes):\n",
    "    lb_enc = LabelEncoder().fit(np.array(classes).reshape(-1,1))\n",
    "    label_encoded = lb_enc.transform(x)   \n",
    "    enc = OneHotEncoder(sparse=False).fit(lb_enc.transform(np.array(classes).reshape(-1,1)).reshape(-1,1))\n",
    "    enc.transform(label_encoded.reshape(-1,1))\n",
    "    return enc.transform(label_encoded.reshape(-1,1)), lb_enc\n",
    "\n",
    "## List of all classes of all columns\n",
    "classes = {}\n",
    "## List of one-hot encoded values for all columns\n",
    "y_cols = []\n",
    "## List of label encoders of all columns\n",
    "lb = []\n",
    "lb_dict = {}\n",
    "## List of column names (as defined in the header of final_data_annotation.csv)\n",
    "columns = ['Col' + str(i) for i in range(3, 8)]\n",
    "\n",
    "for col in columns:\n",
    "    classes[col] = list(set(data[col]))\n",
    "    y_c, lb_c = one_hot_categorical(data[col], classes[col])\n",
    "    y_cols.append(y_c)\n",
    "    lb.append(lb_c)\n",
    "    lb_dict[col] = dict(zip(lb_c.transform(lb_c.classes_).astype(str), (lb_c.classes_).astype(str)))\n",
    "\n",
    "with open(save_model_path + 'label_encodings.json', \"w\") as json_file:\n",
    "    json.dump(lb_dict, json_file)  \n",
    "    \n",
    "tot_num_classes = np.sum(len(c) for c in classes.values())\n",
    "\n",
    "split_idx = [np.sum(y_cols[j].shape[1] for j in range(i)) for i in range(len(y_cols))][1:]\n",
    "\n",
    "## Preparing dataframe that will be used as an input to flow_from_directory\n",
    "targets = np.concatenate(y_cols, axis = 1)\n",
    "image_files = pd.DataFrame(targets)\n",
    "image_files['filename'] = data['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining augmentation techniques\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "seq = iaa.Sequential(\n",
    "    [\n",
    "        # apply the following augmenters to most images\n",
    "        # iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "        iaa.OneOf([\n",
    "            sometimes(iaa.CropAndPad(percent=(-0.05, 0.1))), # zoom in\n",
    "            sometimes(iaa.Affine(scale={\"x\": (0.6, 1.2), \"y\": (0.6, 1.2)})) # zoom out\n",
    "        ]), \n",
    "        # execute 1 to 2 of the following augmenters per image\n",
    "        sometimes(iaa.Affine(translate_px={\"x\": (0, 25), \"y\": (0, 25)}, # horizontal/vertical shift\n",
    "                            rotate = (-25, 25),\n",
    "                            shear = (-15, 15))), \n",
    "        iaa.SomeOf((1, 4),\n",
    "                   [iaa.OneOf([\n",
    "                       iaa.PerspectiveTransform(scale=(0.01, 0.07)),\n",
    "                       iaa.Sharpen(alpha=(0, 0.5), lightness=(0.75, 1.5)),\n",
    "                       iaa.PiecewiseAffine((0.0, 0.01)), # local distortions\n",
    "                       iaa.GaussianBlur(sigma=(0, 0.7))\n",
    "                   ]),\n",
    "                    sometimes(iaa.Dropout((0.01, 0.02), per_channel=0.5)),\n",
    "                    iaa.AdditiveGaussianNoise(loc=32, scale=0.01*255), # white noise\n",
    "                    iaa.Add((-20, 50)), # brightness\n",
    "                    iaa.OneOf([\n",
    "                        iaa.LinearContrast(alpha=(0.5,1.2), per_channel = True),\n",
    "                        iaa.ContrastNormalization((0.5, 1.0))\n",
    "                    ])\n",
    "            ], random_order=True)\n",
    "    ], random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining Data Generator\n",
    "def split_outputs(generator, idx):\n",
    "    while True:\n",
    "        data = next(generator)\n",
    "        x = data[0]\n",
    "        y = np.split(data[1], idx, axis=1)\n",
    "        yield x, y\n",
    "\n",
    "def read_data(img_data_gen, base_dir, in_df, idx, path_col = 'filename',\n",
    "                        y_col = 'targets', batch_size = 8, n_classes = 38, rows = 224, cols = 224):\n",
    "    df_gen = img_data_gen.flow_from_dataframe(in_df, base_dir,\n",
    "                                              x_col = 'filename', y_col= list(range(n_classes)),\n",
    "                                              has_ext = False, target_size = (rows, cols),\n",
    "                                              color_mode = 'rgb', class_mode = 'other',\n",
    "                                              batch_size = batch_size)\n",
    "    return split_outputs(df_gen, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating image generators for train and validation\n",
    "img_train_gen = ImageDataGenerator(rescale=1/255, preprocessing_function = seq.augment_image)\n",
    "img_val_gen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "## Splitting annotated images into training and validation\n",
    "## train\n",
    "train_ids = list(set(data.loc[data['split'] == 'train', 'filename']))\n",
    "train_df = image_files.loc[image_files['filename'].isin(train_ids),:].drop_duplicates().reset_index(drop = True)\n",
    "print(str(len(train_ids)) + ' Training Images')\n",
    "train_gen = read_data(img_train_gen, train_data_path, train_df, idx = split_idx,\n",
    "                                batch_size = bs, n_classes = tot_num_classes, rows = img_rows, cols = img_cols)\n",
    "## validation\n",
    "val_ids = list(set(data.loc[data['split'] == 'val', 'filename']))\n",
    "val_df = image_files.loc[image_files['filename'].isin(val_ids),:].drop_duplicates().reset_index(drop = True)\n",
    "print(str(len(val_ids)) + ' Validation Images')\n",
    "val_gen = read_data(img_val_gen,validation_data_path, val_df,idx = split_idx,\n",
    "                              batch_size = bs,  n_classes = tot_num_classes, rows = img_rows, cols = img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(base_model, img_channels, img_w, img_h, classes_list):    \n",
    "    \"\"\"Builds and returns a learning model.\n",
    "    img_channels: the number of channels in the input images (1 for grayscale,\n",
    "        or 3 for RGB).\n",
    "    img_w: the width (in pixels) of the input images.\n",
    "    img_h: the height of the input images.\n",
    "    classes_list: the number of classes that the data will have (for each code) - this dictates\n",
    "        the number of values produced in the output layer.\n",
    "    Returns:\n",
    "    A deep neural network model.\n",
    "    \"\"\"\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = Conv2D(filters = 512,kernel_size = 3,strides=(1,1), name = 'fc_start')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Col 3\n",
    "    x3 = GlobalAveragePooling2D()(x)\n",
    "    x3 = Dense(1024, activation='relu')(x3)\n",
    "    x3 = Dropout(0.2)(x3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = Dense(512, activation='relu')(x3)\n",
    "    x3 = Dropout(0.2)(x3)\n",
    "    out3 = Dense(len(classes_list['Col3']), activation='softmax', name = 'col3')(x3)\n",
    "\n",
    "    # Col 4\n",
    "    x4 = Conv2D(filters = 256,kernel_size = 3,strides=(1,1))(x)\n",
    "    x4 = GlobalAveragePooling2D()(x4)\n",
    "    x4 = Dense(1024, activation='relu')(x4)\n",
    "    x4 = Dropout(0.5)(x4)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = Dense(512, activation='relu')(x4)\n",
    "    x4 = Dropout(0.5)(x4)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = Dense(512, activation='relu')(x4)\n",
    "    x4 = Dropout(0.5)(x4)\n",
    "    out4 = Dense(len(classes_list['Col4']), activation='softmax', name = 'col4')(x4)\n",
    "\n",
    "    # Col 5\n",
    "    x5 = GlobalAveragePooling2D()(x)\n",
    "    x5 = Dense(1024, activation='relu')(x5)\n",
    "    x5 = Dropout(0.2)(x5)\n",
    "    x5 = BatchNormalization()(x5)\n",
    "    x5 = Dense(512, activation='relu')(x5)\n",
    "    x5 = Dropout(0.2)(x5)\n",
    "    out5 = Dense(len(classes_list['Col5']), activation='softmax', name = 'col5')(x5)\n",
    "\n",
    "    # Col 6\n",
    "    x6 = GlobalAveragePooling2D()(x)\n",
    "    x6 = Dense(1024, activation='relu')(x6)\n",
    "    x6 = Dropout(0.2)(x6)\n",
    "    x6 = BatchNormalization()(x6)\n",
    "    x6 = Dense(512, activation='relu')(x6)\n",
    "    x6 = Dropout(0.2)(x6)\n",
    "    out6 = Dense(len(classes_list['Col6']), activation='softmax', name = 'col6')(x6)\n",
    "\n",
    "    # Col 7\n",
    "    x7 = Conv2D(filters = 256,kernel_size = 3,strides=(1,1))(x)\n",
    "    x7 = GlobalAveragePooling2D()(x7)\n",
    "    x7 = Dense(1024, activation='relu')(x7)\n",
    "    x7 = Dropout(0.5)(x7)\n",
    "    x7 = BatchNormalization()(x7)\n",
    "    x7 = Dense(512, activation='relu')(x7)\n",
    "    x7 = Dropout(0.5)(x7)\n",
    "    out7 = Dense(len(classes_list['Col7']), activation='softmax', name = 'col7')(x7)\n",
    "\n",
    "    return [out3, out4, out5, out6, out7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining f1 Score - for model evaluation\n",
    "def f1(y_true, y_pred):\n",
    "\n",
    "    y_true = tf.cast(y_true, tf.float64)\n",
    "    y_pred = tf.cast(y_pred, tf.float64)\n",
    "\n",
    "    TP = tf.count_nonzero(y_pred * y_true, axis=0, dtype = tf.float64)\n",
    "    FP = tf.count_nonzero(y_pred * (y_true - 1), axis=0, dtype = tf.float64)\n",
    "    FN = tf.count_nonzero((y_pred - 1) * y_true, axis=0, dtype = tf.float64)\n",
    "\n",
    "    add_dummy = lambda x: x + K.epsilon()\n",
    "    precision = TP /  tf.map_fn(add_dummy, (TP + FP))\n",
    "    recall = TP / tf.map_fn(add_dummy, (TP + FN))\n",
    "    f1 = 2 * precision * recall / tf.map_fn(add_dummy, (precision + recall))\n",
    "\n",
    "    weights = tf.reduce_sum(y_true, axis=0)\n",
    "    weights /= tf.reduce_sum(weights)\n",
    "    return tf.reduce_sum(f1 * weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "## Defining the input image size\n",
    "SHAPE = (img_rows, img_cols, img_channels)\n",
    "\n",
    "base_model = ResNet50(include_top=False, weights=None, input_shape = SHAPE)\n",
    "base_model.load_weights(model_weights_path)\n",
    "\n",
    "print('freezing entire base model ...\\n')\n",
    "# Freezing entire base model\n",
    "for layer in base_model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_output = build_model(base_model, img_channels, img_rows, img_cols, classes)\n",
    "model = Model(inputs = base_model.input, outputs = model_output)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(save_model_path + model_name +'_checkpoint.h5',\n",
    "                                   monitor='val_loss', \n",
    "                                   mode = 'auto', save_best_only=True, verbose=2)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode = 'auto',patience = 5, verbose=2)\n",
    "# For cyclical Learning Rate\n",
    "sched = LR_Cycle(iterations = np.ceil(len(train_ids)/bs),\n",
    "                 cycle_mult = 2)\n",
    "\n",
    "# cbks = [model_checkpoint,early_stopping,reduce_lr]\n",
    "cbks1 = [model_checkpoint,early_stopping]\n",
    "cbks2 = [model_checkpoint,early_stopping, sched]\n",
    "\n",
    "opt = SGD(lr = 5 * 1e-2, momentum = 0.9)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=[f1,\"accuracy\"])\n",
    "\n",
    "print('running 2 epochs with non-trainable base layers ...\\n')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch = np.ceil(len(train_ids)/bs),\n",
    "                              epochs = 2,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = np.ceil(len(val_ids)/bs),\n",
    "                              use_multiprocessing = True,\n",
    "                              callbacks = cbks1)\n",
    "\n",
    "\n",
    "\n",
    "print('unfreezing all layers ...\\n')\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "# For Differential Learning Rate\n",
    "split_layer_1 = [layer for layer in model.layers if layer.name == model_split_1][0]\n",
    "split_layer_2 = [layer for layer in model.layers if layer.name == model_split_2][0]\n",
    "\n",
    "opt = SGD_dlr(split_l1 = split_layer_1,\n",
    "              split_l2 = split_layer_2,\n",
    "              lr = [1e-10, 1e-6, 1e-3],\n",
    "              momentum = 0.9)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=[f1,\"accuracy\"])\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch = np.ceil(len(train_ids)/bs),\n",
    "                              epochs = nb_epoch - 2,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = np.ceil(len(val_ids)/bs),\n",
    "                              use_multiprocessing = True,\n",
    "                              callbacks = cbks2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save model and weights\n",
    "model_json = model.to_json()\n",
    "with open(save_model_path + model_name + '_model.json', \"w\", encoding = 'utf-8') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(save_model_path + model_name + '_weights.h5')\n",
    "\n",
    "#Calculate execution time\n",
    "end = time.time()\n",
    "dur = end-start\n",
    "\n",
    "if dur<60:\n",
    "    print(\"Execution Time:\",dur,\"seconds\")\n",
    "elif dur>60 and dur<3600:\n",
    "    dur=dur/60\n",
    "    print(\"Execution Time:\",dur,\"minutes\")\n",
    "else:\n",
    "    dur=dur/(60*60)\n",
    "    print(\"Execution Time:\",dur,\"hours\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the true annotations\n",
    "data = pd.read_csv(annotation_path, encoding = 'latin-1')\n",
    "\n",
    "image_names = [i for i in os.listdir(test_path) if 'Thumbs' not in i]\n",
    "\n",
    "data['filename'] = data['filename'] + '.jpg'\n",
    "test_df = data.loc[data['filename'].isin(image_names)].drop_duplicates().reset_index(drop = True)\n",
    "print(data.shape[0], 'test images found ...')\n",
    "\n",
    "model_path = save_model_path\n",
    "## Extract the encodings\n",
    "lb_dict = json.loads(open(model_path + 'label_encodings.json').read())\n",
    "lb = []\n",
    "## List of all classes of all columns\n",
    "classes = {}\n",
    "## List of column names (as defined in the header of final_data_annotation.csv)\n",
    "columns = ['Col' + str(i) for i in range(3, 8)]\n",
    "for col in columns:\n",
    "    classes[col] = list(lb_dict[col].values())\n",
    "    lb.append(lb_dict[col])\n",
    "tot_num_classes = np.sum(len(c) for c in classes.values())\n",
    "\n",
    "## Load model and weights\n",
    "print('loading the model ...\\n')\n",
    "json_file = open(model_path + 'resnet50_multioutput_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json, \n",
    "                        custom_objects={'f1':f1})\n",
    "model.load_weights(model_path + 'resnet50_multioutput_checkpoint.h5')\n",
    "\n",
    "## Defining augmentation techniques for Test Time Augmentation\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "seq = iaa.Sequential(\n",
    "    [\n",
    "        # apply the following augmenters to most images\n",
    "        iaa.OneOf([\n",
    "            sometimes(iaa.CropAndPad(percent=(-0.05, 0.1))), # zoom in\n",
    "            sometimes(iaa.Affine(scale={\"x\": (0.6, 1.2), \"y\": (0.6, 1.2)})) # zoom out\n",
    "        ]), \n",
    "        # execute 1 to 2 of the following augmenters per image\n",
    "        sometimes(iaa.Affine(translate_px={\"x\": (0, 10), \"y\": (0, 10)},\n",
    "                            rotate = (-25, 25)\n",
    "                            )\n",
    "                 ), # horizontal/vertical shift\n",
    "        iaa.SomeOf((1, 4),\n",
    "                   [iaa.OneOf([\n",
    "                       iaa.Sharpen(alpha=(0, 0.5), lightness=(0.75, 1.5)),\n",
    "                       iaa.GaussianBlur(sigma=(0, 0.7))\n",
    "                   ]),\n",
    "                    sometimes(iaa.Dropout((0.01, 0.02), per_channel=0.5)),\n",
    "                    iaa.AdditiveGaussianNoise(loc=32, scale=0.01*255), # white noise\n",
    "                    iaa.Add((-20, 50)), # brightness\n",
    "                    iaa.OneOf([\n",
    "                        iaa.LinearContrast(alpha=(0.5,1.2), per_channel = True),\n",
    "                        iaa.ContrastNormalization((0.5, 1.0))\n",
    "                    ])\n",
    "            ], random_order=True)\n",
    "    ], random_order=True)\n",
    "\n",
    "## Get actual code\n",
    "y_true = [np.array(test_df[col].astype(str)) for col in columns]\n",
    "\n",
    "## Get predicted code\n",
    "pred = []\n",
    "for ind in range(test_df.shape[0]):\n",
    "\n",
    "    image_n = test_df.loc[ind, 'filename']\n",
    "    ## Read Image\n",
    "    img = cv2.cvtColor(cv2.imread(test_path + '/' + image_n), cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (img_rows, img_cols))\n",
    "\n",
    "    images_l = []\n",
    "    ## Original Image\n",
    "    images_l.append(img/255)\n",
    "    ## Augmented Images\n",
    "    for aug in range(15):\n",
    "        images_l.append(seq.augment_image(img)/255)\n",
    "\n",
    "    img_predictions = []\n",
    "    for image in images_l:\n",
    "        img_predictions.append(model.predict(image.reshape((-1,img_rows, img_cols, 3))))\n",
    "    predictions = []\n",
    "    label_pred = []\n",
    "    for c in range(len(classes)):\n",
    "        class_pred = np.array(([(img_predictions[j][c]).reshape(-1) for j in range(len(img_predictions))]))\n",
    "        predictions.append(np.mean(class_pred, axis = 0))\n",
    "        label_pred.append(lb[c][str(np.argmax(predictions[c]))])\n",
    "    pred.append(label_pred)\n",
    "\n",
    "y_pred = []\n",
    "for c in range(len(classes)):\n",
    "    y_pred.append(np.array([i[c] for i in pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=False):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_model_report(writer, folder, true, pred, cols, lb):\n",
    "\n",
    "    total_samples = len(true[0])\n",
    "    start = 0\n",
    "    m = []\n",
    "    print(str(['Column', 'Precision', 'Recall', 'Accuracy']))\n",
    "    for i in range(len(cols)):\n",
    "\n",
    "        class_true = true[i]\n",
    "        class_pred = pred[i]\n",
    "\n",
    "        # Accuracy Metrics\n",
    "        prf = np.round(metrics.precision_recall_fscore_support(class_true, class_pred, average='weighted')[:-1],4)\n",
    "        acc = np.round(metrics.accuracy_score(class_true, class_pred),4)\n",
    "        metric_list = [cols[i]]\n",
    "        metric_list.extend(prf)\n",
    "        metric_list.extend([acc])\n",
    "        m.append(metric_list)\n",
    "        print(str(metric_list))\n",
    "\n",
    "        # Confusion Matrix\n",
    "        report = metrics.confusion_matrix(class_true, class_pred, labels = list(lb[i].values()))\n",
    "        plot_confusion_matrix(report, list(lb[i].values()), title = cols[i])\n",
    "        df = pd.DataFrame(report, columns = list(lb[i].values()), index = list(lb[i].values()))\n",
    "        df.to_excel(writer,sheet_name='CM_' + folder ,startrow = start , startcol=0)   \n",
    "\n",
    "        # Class Scores\n",
    "        df_class_score = pd.DataFrame(index = lb[i].values())\n",
    "        df_class_score['Precision'] = metrics.precision_score(class_true, class_pred,\n",
    "                                                              average = None, labels = list(lb[i].values()))\n",
    "        df_class_score['Recall'] = metrics.recall_score(class_true, class_pred,\n",
    "                                                        average = None, labels = list(lb[i].values()))\n",
    "        df_class_score['F1'] = metrics.f1_score(class_true, class_pred,\n",
    "                                                average = None, labels = list(lb[i].values()))\n",
    "        df_class_score.to_excel(writer, sheet_name = folder + '_score', startrow = start, startcol = 0)\n",
    "\n",
    "        start = start + len(list(lb[i].values())) + 2\n",
    "\n",
    "    metrics_df = pd.DataFrame(m, columns = ['Column','Precision','Recall','F1','Accuracy'])\n",
    "    metrics_df.to_excel(writer, sheet_name=folder, index = False)\n",
    "    pd.DataFrame({'Samples':[total_samples]}).to_excel(writer, sheet_name=folder, startrow = 8, index = False)\n",
    "    print()\n",
    "\n",
    "    return writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(model_path + 'overall_report.xlsx', engine='xlsxwriter')\n",
    "writer = cm_model_report(writer, 'test', y_true, y_pred, columns, lb) \n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = pd.DataFrame(y_true).T\n",
    "actuals.columns = ['Actual_' + col for col in columns]\n",
    "predicted = pd.DataFrame(y_pred).T\n",
    "predicted.columns = ['Predicted_' + col for col in columns]\n",
    "df = pd.concat([test_df['filename'], actuals, predicted], axis = 1)\n",
    "df.to_csv(model_path + 'actuals_vs_predicted.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
